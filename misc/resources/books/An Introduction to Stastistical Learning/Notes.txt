#region Had To Look Up
3 different measurements of dispersion = {Standard Deviation, Average Absolute Deviation, Mean Absolute Deviation}

SD()     = Standard Deviation
SD()^2   = Variance
VAR()^.5 = Standard Deviation
VAR()    = Variance
sigma    = Standard Deviation
sigma^2  = Variance
E()      = Expected Value

MSE(X)  = E[f(X) - f'(X)]^2 = Var[f'(X)] + Bias[f'(x)]^2 + Var(e)
Bias(X) = E[f'(X)] - E(f(X)) (https://en.wikipedia.org/wiki/Bias_of_an_estimator) (
E(X)    = Avg(X) (expected value) (https://en.wikipedia.org/wiki/Expected_value) (19, 34)
Var(X)  = Avg[(X - Avg(X))^2] = E[(X - E[X])^2] (p19 and Wikipedia) (variance) (https://en.wikipedia.org/wiki/Variance) (19,34,38)
I()     = indicator variable (https://en.wikipedia.org/wiki/Dummy_variable_(statistics)) (37, 39)
#endregion

#region Chapter 1
Types of learning 
    > Supervised (p1)
    > Unsupervised (p1)

Types of output    
    > Continuous (aka Quantitative?) (p2) why can't discrete outcomes be Quantitative? Also, often referred to  as a regression problem? What does Regression mean?
    > Discrete (note the doesn't use the term discrete, I did) (aka qualitative/categorical) (p2-3)

There are learning classes of for which there are no "Outputs"? (p4). But isn't the "output" in this case whatever pattern or insight we glean from our research?

n       = |observations|
p       = |variables or predictors|
x-sub-0 =  a vector of size p containing one of each predictor. Also known as aa single obersvation, n.

scalar = a
vector = (aka tuple) 1xn matrix
matrix =

Commutative = changing the order of operands doesn't change the result (e.g. a+b = b+a)
Associative = changing the order of a sequence doesn't change the result (e.g. [a+b]+c = a+[b+c])

"A central problem in all statistical learning situations involves choosing the best method for a given application." (p12)
#endregion

#region Chapter 2
Y = f(X) + e (p16)

In Y = f(X) + e, Avg(e) will always be 0. While Var(e) will never be 0. (p16)

f(X) represents the "ideal" relationship between X and Y. For example, if X is time and Y the is velocity of falling object, then the ideal relationship is Y = f(X) = 9.81 * X. (p18)

There are two kinds of errors that can be captured in Y = f(x) + e. One is explicitly defined: e. It is called the irreducible error. The other is implicit: the deviation of our calculated f(X) from the platonic ideal. It is calle dthe reducible error because we can always improve f(X). (p18)

When squaring the difference we can simply average out e because 

Remember, our learning algorithms are trying to discover f(X) NOT f(x) + e. Through observations we might be able to discover e but that does nothing to help us predict Y since we have no way to predict e even with its range. (p19)

Y = f(X) + e
Y' = f'(X)
E(Y) = f(X) + avg(e)
E(Y - Y') = f(x) - f'(x)

Reasons for calculating f(X)
    > Prediction: to easily or cheaply determine Y given X without having to make real life observations (e.g. how fast will my plan fall out of the sky if I remove its wings?)
    > Inference: to understand how the various variables, X, impact Y (e.g. x1 might decrease Y while x2 increases it Y = f(x1, x2) = x2 - x1). (p17-19)
    
Fundamental relationships types between Y and X, i.e., f in Y = f(X)
    > Linear
    > non-linear

Fundamentals methods for determining f(X)
    > Parameteric: pick a pattern or model and then simply figure which values to assign the paramaters of that model to optimize it. (The least squares is an example of the parametric method. First, we pick the model "linear". Then, we adjust the parameters to minimize the squared distances.) (p21-22) 
    > Non-Parametric: These need a lot more observations than Parametric approaches because they don't assume a given form.
    
When creating "synthetic observations" the Y = f(x) + e formula is used. First a "synthetic" f(x) is created to generate values. Then for every generated observations a random value, e, is added. By one definition then the test of a learning algorithm is to determine f(x)... In theory, if e is truly random there shouldn't be any possible f(x) that can accurately capture it.

What if there is no f(x) to discover? Or what if it only accounts for .00001% of the relationship? Can we assume there is *always* a relationship between two variables since we lived in a closed universe?

"In general, as the flexibility of a method increases, its interpretability decreases." (p25) by "interpret" I think they mean to explain what is going on over many observations in a simple sentence (e.g. when x increases y increases)

The more "flexible" a learning algorithm the higher the risk of overfitting (p25)

Supervised Learning - there is an output that can validate as correct or not. The validation would be the "supervising" step. Such validation may not be done, but the algorithm is still considered "supervised" as long as it is possible to validate.
Unsupervised Learning - there isn't an output and so it isn't possible to validate the result against known observations. Or perhaps the output can't be reduced to a single quantifiable variable. The output might be astronomically large and require exponential time to check (this can also be called semi-supervised).

Quantitative problems tend to be referred to as regression problems (p26)
Qualitative problems tend to be referred to as classification problems (p26)

Regressions, of any kind, always output continuous values. Continuous values can be used to answer Qualitative problems (e.g. age, quantitative, can be used to determine if a person is a legal adult, qualitiatve)

MSE = Mean Squared Error (p29) (used primarily for quantitative outputs)

MSE can never be lower than e because no change to f(x) will ever account for e. (p34)
approximate MSE = variance + bias + e, where variance is how much our model changes with different test data and bias is how far off from the actual relationship our model is

linear models often have low variance but high bias
flexible models often have high variance and low bias

"In a real-life situation in which f is unobserved, it is generally not possible to explicitly compute the test MSE, bias, or variance for a statistical learning method. Nevertheless, one should always keep the bias-variance trade-off in mind." (p36)

Test Error Rate - Avg(I(ym0 != yt0)). Because I is either 1 or 0 the average will give us the percentage that were incorrect. (p37)

I() stands for an "Indicator Variable" which basically means a qualitative variable (in the above example the output of I() is either 1 or 0) (p37)

Why is the Bayes error rate comporable to the irreducible error rate? (p39)
    > because the Bayes Classifier assumes an ideal situation where we have used all information available to us to make the best decision we can.
    > The Bayes Classifier doesn't say what the classification "Should" be. It says what the "Classification" will most likely be.

In a classification problem there are two possibilities our p is in the Class we say or not.
    > we can represent this P = chance p is in our chosen class and 1-p = chance p is not in chosen class.
    > If we assume that our p is a perfect guess given the information available to us then 1-p can't be reduced any more.
       
How is the Bayes classifier any differernt from Y = f(X) + e?

Bayes, what is the best guess we can make given the X that we have?

When using KNN the smaller K is the more flexible our algorithm is and the bigger K is the less flexible our algorithm is. (p40)

Classification learning algorithms exhibit the same U curve with Test Data as flexibility increases or decreses. (p40)
#endregion